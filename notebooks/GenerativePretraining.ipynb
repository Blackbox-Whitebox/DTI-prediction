{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5722642c",
   "metadata": {},
   "source": [
    "# GOALS\n",
    "- Pretrain Sequence model on protein sequences (GOAL to create a model that can do next token prediction accurately on protein sequences)\n",
    "- Pretrain Sequence model on SMILES of Drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbe0d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.data import Dataset, DataLoader\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dfcbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, tokens): \n",
    "        special_tokens = [\"PAD\", \"SOS\", \"EOS\"]\n",
    "        self.tokens = tokens + special_tokens\n",
    "        self.token_ix = {t:i for i, t in enumerate(self.tokens)}\n",
    "        self.ix_token = {i:t for i,t in enumerate(self.tokens)}\n",
    "\n",
    "    def encode(self, seq, max_len=None):\n",
    "        encoded = [self.token_ix[\"SOS\"]] + [self.token_ix[t] for t in seq] + [self.token_ix[\"EOS\"]]\n",
    "        if max_len:\n",
    "            if len(encoded) < max_len:\n",
    "                encoded += [self.token_ix[\"PAD\"]]*(max_len-len(encoded))\n",
    "                \n",
    "        return encoded\n",
    "                \n",
    "    def decode(self, seq):\n",
    "        return [self.ix_token[t] for t in seq]\n",
    "\n",
    "class ProteinVocab(Vocab):\n",
    "    def __init__(self):\n",
    "        # 20 amino acids\n",
    "        tokens = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y']\n",
    "        super().__init__(tokens)\n",
    "        \n",
    "class SMILEVocab(Vocab):\n",
    "    def __init__(self):\n",
    "        tokens = ['#','(',')','+','-','.','/','1','2','3','4','5','6','7','8','=','@',\n",
    "                  'A','B','C','F','G','H','I','K','L','M','N','O','P','S','T','V','W','Z',\n",
    "                  '[','\\\\',']','a','b','d','e','g','i','l','n','o','r','s','t','u']\n",
    "        super().__init__(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01cb325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_examples(vocab, sequence, seq_len):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    sequence = vocab.encode(sequence)\n",
    "    \n",
    "    for i in range(len(sequence)-seq_len-1):\n",
    "        x.append(sequence[i:i+seq_len])\n",
    "        y.append([sequence[i+1]])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66f3e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_vocab = ProteinVocab()\n",
    "smile_vocab = SMILEVocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63975c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d4d62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_data = {\n",
    "    \"x\": [],\n",
    "    \"y\": []\n",
    "}\n",
    "\n",
    "smile_data = {\n",
    "    \"x\": [],\n",
    "    \"y\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aea0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut_id_to_seq = json.load(open(\"../data/uniprotid_to_seq.json\", 'r'))\n",
    "db_id_to_smile = json.load(open(\"../data/databankid_to_smile.json\", 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c082e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein sequences\n",
    "for uniprot_id in tqdm(list(ut_id_to_seq.keys())):\n",
    "    protein_sequence = ut_id_to_seq[uniprot_id]\n",
    "    x, y = generate_examples(protein_vocab, protein_sequence, seq_len)\n",
    "    protein_data[\"x\"]+=x\n",
    "    protein_data[\"y\"]+=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c8fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(protein_data[\"x\"]), len(protein_data[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMILE sequences\n",
    "for drugbank_id in tqdm(list(db_id_to_smile.keys())):\n",
    "    smile_seq = db_id_to_smile[drugbank_id]\n",
    "    x, y = generate_examples(smile_vocab, smile_seq, seq_len)\n",
    "    smile_data[\"x\"]+=x\n",
    "    smile_data[\"y\"]+=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b837e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(smile_data[\"x\"]), len(smile_data[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf4ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_data[\"x\"] = torch.Tensor(protein_data[\"x\"])\n",
    "protein_data[\"y\"] = torch.Tensor(protein_data[\"y\"])\n",
    "\n",
    "smile_data[\"x\"] = torch.Tensor(smile_data[\"x\"])\n",
    "smile_data[\"y\"] = torch.Tensor(smile_data[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e3981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_data_indices = torch.randperm(protein_data[\"x\"].shape[0])\n",
    "smile_data_indices = torch.randperm(smile_data[\"x\"].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a36263",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pct = .8\n",
    "\n",
    "protein_train_indices = protein_data_indices[:int(train_pct*protein_data_indices.shape[0])]\n",
    "protein_test_indices = protein_data_indices[int(train_pct*protein_data_indices.shape[0]):]\n",
    "\n",
    "smile_train_indices = smile_data_indices[:int(train_pct*smile_data_indices.shape[0])]\n",
    "smile_test_indices = smile_data_indices[int(train_pct*smile_data_indices.shape[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b21a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_train_indices.shape, protein_test_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df33e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "smile_train_indices.shape, smile_test_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f478cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data[\"y\"])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[\"x\"][idx]\n",
    "        y = self.data[\"y\"][idx][0]\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afd9661",
   "metadata": {},
   "source": [
    "## Step 1.5 Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe92cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1, dropout=0, bidirectional=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, num_layers=num_layers, dropout=dropout, batch_first=True, bidirectional=bidirectional)\n",
    "        self.out = nn.Linear(hidden_size*2 if self.bidirectional else hidden_size, vocab_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embedding(x)\n",
    "        x, hidden = self.gru(x, hidden)\n",
    "        x = self.out(x[:, -1])\n",
    "        return x, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b5f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "lr = 3e-4\n",
    "lossfn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6d4f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train, test, optimizer, epochs):\n",
    "    train_loss_over_time = []\n",
    "    test_loss_over_time = []\n",
    "    train_accuracy_over_time = []\n",
    "    test_accuracy_over_time = []\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        train_loss_epoch = []\n",
    "        test_loss_epoch = []\n",
    "\n",
    "        train_accuracy_epoch = []\n",
    "        test_accuracy_epoch = []\n",
    "        \n",
    "        for x, y in train:\n",
    "            optimizer.zero_grad()\n",
    "            x = x.long()\n",
    "            y = y.long()\n",
    "\n",
    "            p, _ = net(x)\n",
    "            loss = lossfn(p, y)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_epoch.append(loss.item())\n",
    "            accuracy = (p.argmax(-1) == y).sum()/p.shape[0]\n",
    "            train_accuracy_epoch.append(accuracy.item())\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            for x, y in test:\n",
    "                x = x.long()\n",
    "                y = y.long()\n",
    "\n",
    "                p, _ = net(x)\n",
    "                loss = lossfn(p, y)\n",
    "                test_loss_epoch.append(loss.item())\n",
    "                accuracy = (p.argmax(-1) == y).sum()/p.shape[0]\n",
    "                test_accuracy_epoch.append(accuracy.item())\n",
    "                \n",
    "        train_loss_epoch = sum(train_loss_epoch)/len(train_loss_epoch)\n",
    "        test_loss_epoch = sum(test_loss_epoch)/len(test_loss_epoch)\n",
    "        train_accuracy_epoch = sum(train_accuracy_epoch)/len(train_accuracy_epoch)\n",
    "        test_accuracy_epoch = sum(test_accuracy_epoch)/len(test_accuracy_epoch)\n",
    "\n",
    "        train_loss_over_time.append(train_loss_epoch)\n",
    "        train_accuracy_over_time.append(train_accuracy_epoch)\n",
    "        test_loss_over_time.append(test_loss_epoch)\n",
    "        test_accuracy_over_time.append(test_accuracy_epoch)\n",
    "        \n",
    "        print(f\"Epoch : {epoch+1} | Test Loss : {test_loss_epoch:.4f} | Test Accuracy : {test_accuracy_epoch:.4f} | Train Loss : {train_loss_epoch:.4f} | Train Accuracy : {train_accuracy_epoch:.4f}\")\n",
    "        \n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"train_loss_over_time\": train_loss_over_time,\n",
    "        \"test_loss_over_time\": train_loss_over_time,\n",
    "        \"train_accuracy_over_time\": train_accuracy_over_time,\n",
    "        \"test_accuracy_over_time\": test_accuracy_over_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bacb2c9",
   "metadata": {},
   "source": [
    "### Model #1: - single layer unidirectional gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfee83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GRUModel(\n",
    "    vocab_size=len(protein_vocab.tokens),\n",
    "    embed_size=64,\n",
    "    hidden_size=128,\n",
    "    num_layers=1,\n",
    "    dropout=0,\n",
    "    bidirectional=False\n",
    ")\n",
    "\n",
    "train = SequenceDataset({\n",
    "    \"x\": protein_data[\"x\"][protein_train_indices],\n",
    "    \"y\": protein_data[\"y\"][protein_train_indices]\n",
    "})\n",
    "\n",
    "test = SequenceDataset({\n",
    "    \"x\": protein_data[\"x\"][protein_test_indices],\n",
    "    \"y\": protein_data[\"y\"][protein_test_indices]\n",
    "})\n",
    "\n",
    "train = DataLoader(train, batch_size=128, shuffle=True)\n",
    "test = DataLoader(test, batch_size=128, shuffle=True)\n",
    "\n",
    "optimized = train(model=net, train=train, test=test, optimizer=optimizer, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e7416",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = optimized[\"model\"]\n",
    "train_loss_over_time = optimized[\"train_loss_over_time\"]\n",
    "train_accuracy_over_time = optimized[\"train_accuracy_over_time\"]\n",
    "test_loss_over_time = optimized[\"test_loss_over_time\"]\n",
    "test_accuracy_over_time = optimized[\"test_accuracy_over_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6788123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(len(train_loss_over_time))+1, \n",
    "        y=train_loss_over_time,\n",
    "        mode='lines',\n",
    "        name='Train loss over time'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(len(test_loss_over_time))+1, \n",
    "        y=test_loss_over_time,\n",
    "        mode='lines',\n",
    "        name='Test loss over time'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Loss over time (Protein GRU)',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title='Cross Entropy Loss'\n",
    ")\n",
    "\n",
    "fig.update_yaxes(type=\"log\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca50278",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(len(train_accuracy_over_time))+1, \n",
    "        y=train_accuracy_over_time,\n",
    "        mode='lines',\n",
    "        name='Train accuracy over time'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(len(test_accuracy_over_time))+1, \n",
    "        y=test_accuracy_over_time,\n",
    "        mode='lines',\n",
    "        name='Test accuracy over time'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Accuracy over time (Protein GRU)',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title='Cross Entropy Loss'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57d5897",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model.state_dict(), \"../checkpoints/pretraining/protein_gru.pth\")\n",
    "torch.save(train_loss_over_time, \"../scalars/pretraining/protein_gru_train_loss_over_time.pth\")\n",
    "torch.save(test_loss_over_time, \"../scalars/pretraining/protein_gru_test_loss_over_time.pth\")\n",
    "torch.save(train_accuracy_over_time, \"../scalars/pretraining/protein_gru_train_accuracy_over_time.pth\")\n",
    "torch.save(test_accuracy_over_time, \"../scalars/pretraining/protein_gru_test_accuracy_over_time.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653626f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GRUModel(\n",
    "    vocab_size=len(smile_vocab.tokens),\n",
    "    embed_size=64,\n",
    "    hidden_size=128,\n",
    "    num_layers=1,\n",
    "    dropout=0,\n",
    "    bidirectional=False\n",
    ")\n",
    "\n",
    "train = SequenceDataset({\n",
    "    \"x\": smile_data[\"x\"][smile_train_indices],\n",
    "    \"y\": smile_data[\"y\"][smile_train_indices]\n",
    "})\n",
    "\n",
    "test = SequenceDataset({\n",
    "    \"x\": smile_data[\"x\"][smile_test_indices],\n",
    "    \"y\": smile_data[\"y\"][smile_test_indices]\n",
    "})\n",
    "\n",
    "train = DataLoader(train, batch_size=128, shuffle=True)\n",
    "test = DataLoader(test, batch_size=128, shuffle=True)\n",
    "\n",
    "optimized = train(model=net, train=train, test=test, optimizer=optimizer, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3b3540",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = optimized[\"model\"]\n",
    "train_loss_over_time = optimized[\"train_loss_over_time\"]\n",
    "train_accuracy_over_time = optimized[\"train_accuracy_over_time\"]\n",
    "test_loss_over_time = optimized[\"test_loss_over_time\"]\n",
    "test_accuracy_over_time = optimized[\"test_accuracy_over_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e8f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(len(train_loss_over_time))+1, \n",
    "        y=train_loss_over_time,\n",
    "        mode='lines',\n",
    "        name='Train loss over time'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(len(test_loss_over_time))+1, \n",
    "        y=test_loss_over_time,\n",
    "        mode='lines',\n",
    "        name='Test loss over time'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Loss over time (Drug GRU)',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title='Cross Entropy Loss'\n",
    ")\n",
    "\n",
    "fig.update_yaxes(type=\"log\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb67e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(len(train_accuracy_over_time))+1, \n",
    "        y=train_accuracy_over_time,\n",
    "        mode='lines',\n",
    "        name='Train accuracy over time'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(len(test_accuracy_over_time))+1, \n",
    "        y=test_accuracy_over_time,\n",
    "        mode='lines',\n",
    "        name='Test accuracy over time'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Accuracy over time (Drug GRU)',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title='Cross Entropy Loss'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0feb508",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model.state_dict(), \"../checkpoints/pretraining/smile_gru.pth\")\n",
    "torch.save(train_loss_over_time, \"../scalars/pretraining/smile_gru_train_loss_over_time.pth\")\n",
    "torch.save(test_loss_over_time, \"../scalars/pretraining/smile_gru_test_loss_over_time.pth\")\n",
    "torch.save(train_accuracy_over_time, \"../scalars/pretraining/smile_gru_train_accuracy_over_time.pth\")\n",
    "torch.save(test_accuracy_over_time, \"../scalars/pretraining/smile_gru_test_accuracy_over_time.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
